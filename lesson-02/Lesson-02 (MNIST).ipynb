{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83155d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST image dataset, and then see what we have.\n",
    "\n",
    "# Note: This data is already divided up in such a way that it can be used for training and testing,\n",
    "# So there is no need to import train_test_split from scikit-learn that we used in lesson-01\n",
    "(train_images_, train_labels), (test_images_, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "# First we will 'normalize' our input data. \n",
    "# This may not always be necessary, but it is good practice, and makes finding the best model easier.\n",
    "# We'll set the numerical values to a range between 0 and 1\n",
    "train_images_, test_images_ = train_images_ / 255.0, test_images_ / 255.0  \n",
    "\n",
    "\n",
    "print(f\"train_images_.shape = {train_images_.shape}\")\n",
    "print(f\"train_labels.shape = {train_labels.shape}\")\n",
    "print(f\"train labels, first 20: {train_labels[0:20]}\")\n",
    "print()\n",
    "print(f\"test labels size: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images are 28 x 28 greyscale captures of handwritten digits, representing numbers from 0 to 9.\n",
    "\n",
    "# We've assigned 60,000 of the images for training, and 10,000 images for testing.\n",
    "# All these data are what we call Labeled Data: data for which we know the right answer.\n",
    "\n",
    "# Now lets take a look at the first one of them: This should be a '5' \n",
    "# according to the train labels output, above.\n",
    "img = train_images_[0]\n",
    "\n",
    "# We can show the grayscale image with PIL (aka pillow)\n",
    "# pil_image = Image.fromarray(img)\n",
    "# pil_image.show()\n",
    "\n",
    "# OR with matplotlip: This image shows grayscale brightness, \n",
    "# with the largest value reprenting the most dark grey.\n",
    "implot = plt.imshow(img)\n",
    "implot.set_cmap('Greys')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef528a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we show the same image with more colorful color map\n",
    "implot = plt.imshow(img)\n",
    "implot.set_cmap('YlGnBu')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e056bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "\n",
    "# What model we want depends on many things, with the most important one being:\n",
    "# (1) how accurate are the predictions.\n",
    "#\n",
    "# Other important metrics to consider are:\n",
    "# (2) how big is the model, \n",
    "# (3) how long does it take to predict new data, and \n",
    "# (4) how long does it take to train.\n",
    "\n",
    "# Picking up where we left off, let's first try using a deep neural network\n",
    "\n",
    "# In lesson-01 we used only Linear or no activation.\n",
    "# For this model, we add relu to add some non-linear type behavior.\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Reshape((784,), input_shape=(28,28)))\n",
    "model.add(layers.Dense(200, kernel_initializer=initializers.RandomNormal(stddev=0.05), activation='relu'))\n",
    "model.add(layers.Dense(100, kernel_initializer=initializers.RandomNormal(stddev=0.05), activation='relu'))\n",
    "model.add(layers.Dense(50, kernel_initializer=initializers.RandomNormal(stddev=0.05), activation='relu'))\n",
    "\n",
    "# 10 neurons, one per output digit. Softmax is commonly used for the output in this categorical situation.\n",
    "model.add(layers.Dense(10, kernel_initializer=initializers.RandomNormal(stddev=0.05), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Note that there was no mention of the input data in this model creation.\n",
    "# The model is independing of the training data (other than the shape of the input).\n",
    "\n",
    "# Let's see how big the model is, and how many trainable parameters there are\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45703336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using only 10 epochs for starters and see how we did.\n",
    "# To keep the training process from using too much memory we'll send in batches of\n",
    "# 64 images, instead of all the images at once.\n",
    "import time\n",
    "start = time.time()\n",
    "model.fit(train_images_, train_labels, epochs=10, batch_size=64, validation_data=(test_images_, test_labels))\n",
    "end = time.time()\n",
    "print(f\"\\nTraining time is {round(end - start, 3)} seconds\\n\")\n",
    "      \n",
    "# Evaluate the model\n",
    "start = time.time()\n",
    "test_loss, test_acc = model.evaluate(test_images_, test_labels)\n",
    "end = time.time()\n",
    "print(\"\\nTest accuracy:\", round(test_acc * 100, 2))\n",
    "print(f\"\\nTesting time for 10,000 examples is {round(end - start, 3)} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e68e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this simple deep learning model we should get a test accuracy of 97.9 +/- 0.4 percent. \n",
    "# We alsm measured the training time and the testing/prediction time.\n",
    "\n",
    "# Note that the training accuracy - which we get when fitting our model to our training data - and \n",
    "# our test accuracy - i.e. how well we can predict our test data - are always at least a little different.  \n",
    "# In fact the val_accuracy (which represents our test accuracy during the fit) stopped getting better in any \n",
    "# substantial way after epoch 5, assuming this is the first time you ran it.\n",
    "\n",
    "# This may be a case of overfitting - and we can take some additional measure to imporove our model and reduce those effects.\n",
    "# These measures are called 'regularization', and I'll discuss them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16200a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try adding a dropout layer\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "model = models.Sequential()\n",
    "dropout_fraction = 0.1\n",
    "\n",
    "model.add(tf.keras.layers.Reshape((784,), input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dropout(dropout_fraction, input_shape=(784,)))\n",
    "model.add(layers.Dense(200, kernel_initializer=initializers.RandomNormal(stddev=0.05), activation='relu'))\n",
    "model.add(layers.Dense(100, kernel_initializer=initializers.RandomNormal(stddev=0.05), activation='relu'))\n",
    "model.add(layers.Dense(50, kernel_initializer=initializers.RandomNormal(stddev=0.05), activation='relu'))\n",
    "\n",
    "# 10 neurons, one per output digit. Softmax is commonly used for the output in this categorical situation.\n",
    "model.add(layers.Dense(10, kernel_initializer=initializers.RandomNormal(stddev=0.05), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Note that there was no mention of the input data in this model creation.\n",
    "# The model is independing of the training data (other than the shape of the input).\n",
    "\n",
    "# Let's see how big the model is, and how many trainable parameters there are\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8eeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using only 10 epochs for starters and see how we did.\n",
    "# To keep the training process from using too much memory we'll send in batches of\n",
    "# 64 images, instead of all the images at once.\n",
    "import time\n",
    "start = time.time()\n",
    "model.fit(train_images_, train_labels, epochs=10, batch_size=64, validation_data=(test_images_, test_labels))\n",
    "end = time.time()\n",
    "print(f\"\\nTraining time is {round(end - start, 3)} seconds\\n\")\n",
    "      \n",
    "# Evaluate the model\n",
    "start = time.time()\n",
    "test_loss, test_acc = model.evaluate(test_images_, test_labels)\n",
    "end = time.time()\n",
    "print(\"\\nTest accuracy:\", round(test_acc * 100, 2))\n",
    "print(f\"\\nTesting time for 10,000 examples is {round(end - start, 3)} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the dropout layer, which literally randomly ignores 10% of the data had the accuracy and\n",
    "# val_accuracy staying much more in step with each other.\n",
    "\n",
    "# In my case the test_accuracy was nearly identical to the no-drop-out case. \n",
    "# More significant is that the training accuracy is more consistent with the test/prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also build a somewhat different model...\n",
    "\n",
    "# Below we build a Convolutional Neural Network or CNN model in tensorflow/keras,\n",
    "# to train and predict these MNIST data.\n",
    "\n",
    "# We need to add one more dimension to the data to get this to feed into the models (and make the tensors flow).\n",
    "print(f\"Before reshaping, train_images_.shape = {train_images_.shape}\")\n",
    "\n",
    "# Add the extra dimension and create a new set of variables.\n",
    "train_images = np.reshape(train_images_, (60000, 28, 28, 1))\n",
    "test_images = np.reshape(test_images_, (10000, 28, 28, 1))\n",
    "\n",
    "print(f\"After reshaping, train_images.shape = {train_images.shape}\")\n",
    "\n",
    "# Recall that we already normalized our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeedd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base model, Sequential, is basically a shell in which we can add layers including\n",
    "# convolutional layers, pooling steps, flattening, and dense neural newtork connections.\n",
    "# These various layers and their connections are specifying the network architecture.\n",
    "model = models.Sequential()\n",
    "\n",
    "# The type and size of the layers, how they change as we move toward the end of the sequence, \n",
    "# how big of a convolutional kernel (here we use 3x3), and what type of activation functions\n",
    "# are used (relu vs tanh vs sigmoid) on the inner layers are just some of the many meta-parameters\n",
    "# that one can exeriment with to find the best model for a given set of input data.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# 10 neurons, one per output digit. Softmax is commonly used for the output in this categorical situation.\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36603fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that this CNN model has only 50% of the Trainable parameters as our deep neural network.\n",
    "\n",
    "# Train the model\n",
    "start = time.time()\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n",
    "end = time.time()\n",
    "print(f\"\\nTraining time is {round(end - start, 3)} seconds\\n\")\n",
    "\n",
    "# Evaluate the model\n",
    "start = time.time()\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "end = time.time()\n",
    "print(\"\\nTest accuracy:\", round(test_acc * 100, 2))\n",
    "print(f\"\\nTesting time for 10,000 examples is {round(end - start, 3)} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8680495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this smaller model we obtained a higher test accuracy, although it did \n",
    "# cost cost us a longer training time (and a longer predition time).\n",
    "\n",
    "# So depending on your cost structure and how often you need to retrain and incorporate the latest data, there may\n",
    "# be a reason to trade off a little accuracy for faster data incorporation (feedback).\n",
    "\n",
    "# The CNN architecture, being more complex involves a greater \n",
    "# number of calculations per the number of trainable parameters.\n",
    "\n",
    "# And CNNs are designed to yield more accurate predictions and analysis of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e118eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should have resulted in about 99% accuracy but I alway like to look at a sample of the failed cases.\n",
    "# Are they really that bad or are we missing something in our model?\n",
    "\n",
    "# So how do we find out which ones were bad? \n",
    "pred_labels_ = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# During the training process, TensorFlow will internally convert numerical labels into the appropriate format.\n",
    "# In this case, as one of 10 categorical labels - depending on the loss function you're using.\n",
    "\n",
    "# So even though we feed it a 5 it converts automatically in the current case to this vector.\n",
    "[0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 0,\n",
    " 0]\n",
    "\n",
    "# or shown as [0,0,0,0,0,1,0,0,0,0] \n",
    "\n",
    "\n",
    "print(f\"pred_labels_.shape = {pred_labels_.shape}\")\n",
    "print(f\"test_labels.shape = {test_labels.shape}\\n\")\n",
    "print(f\"pred_labels_[0] = {np.round(pred_labels_[0], 3)}\\ntest_labels[0] = {test_labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we'll need to do some manipulations to make them more easily comparable.\n",
    "# Create a container of the same size as pred_labels, with only the single value of the best prediction.\n",
    "pred_labels = np.zeros((pred_labels_.shape[0]), dtype=np.int16)\n",
    "\n",
    "# Then fill it with the index with the max values.\n",
    "for i, p in enumerate(pred_labels_):\n",
    "    pred_labels[i] = np.argmax(p)\n",
    "\n",
    "# Now we can compare them and get an array indicating where there is agreement and where not.\n",
    "truth = (pred_labels == test_labels)\n",
    "failure_indexes = np.where(~truth)\n",
    "print(f\"Error rate = {sum(~truth)/len(truth)}\") \n",
    "\n",
    "print(failure_indexes)\n",
    "print(pred_labels[failure_indexes])\n",
    "print(test_labels[failure_indexes])\n",
    "\n",
    "#Look at the first example where there was disagreement(failure).\n",
    "idx = failure_indexes[0][0]\n",
    "\n",
    "# recall that we rescaled (normalized) the orinal train and test images.\n",
    "image_array = (test_images_[idx] * 255)\n",
    "\n",
    "implot = plt.imshow(image_array)\n",
    "implot.set_cmap('Greys')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, Can you see why the computer might get this one confused?\n",
    "# Look at the first value in the lists above to see what is predicted and what was the label.\n",
    "\n",
    "# Lets randomly sample one more from the remaining values\n",
    "idx_value = np.random.choice(failure_indexes[0][1:], size=None, replace=True)\n",
    "idx2 = np.where(failure_indexes[0] == idx_value)[0][0]\n",
    "\n",
    "print(f\"idx2 = {idx_value}\")\n",
    "\n",
    "# Fix these next two lines\n",
    "print('prediction:', pred_labels[failure_indexes][idx2])\n",
    "print('Label:', test_labels[failure_indexes][idx2])\n",
    "\n",
    "image_array2 = (test_images_[idx2] * 255)\n",
    "implot = plt.imshow(image_array2)\n",
    "implot.set_cmap('Greys')\n",
    "plt.colorbar()\n",
    "\n",
    "# Does it make sense that this one is confusing?\n",
    "\n",
    "# If it looks like it is not doing a good job on an obvious number,\n",
    "# there are surely other tricks we can try to implement to bump up our accuracy.\n",
    "#  - Other architectures\n",
    "#  - More training\n",
    "#  - Different types of regularization\n",
    "#  etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142b47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On to Lesson-03"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
